{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    " #!/usr/bin/env python3\n",
    "\n",
    "import gradio as gr\n",
    "import os\n",
    "from os.path import join, dirname\n",
    "from dotenv import load_dotenv\n",
    "from dotenv import load_dotenv\n",
    "import conversational\n",
    "# from conversational import conversatioalChatGPT\n",
    "\n",
    "# from conversation import create_conversation\n",
    "# dotenv_path = join(dirname(__file__), '.env')\n",
    "# print(load_dotenv(dotenv_path))\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import indexdb\n",
    "from langchain.chains import (\n",
    "    ConversationalRetrievalChain,\n",
    "    LLMChain\n",
    ")\n",
    "\n",
    "from langchain import HuggingFaceHub\n",
    "# from utilities import load_api_key\n",
    "\n",
    "\n",
    "# from langchain.vectorstores import Chroma\n",
    "# from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.chat_models import ChatOpenAI , ChatAnthropic\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# from langchain.chains.chat_vector_db.prompts import (CONDENSE_QUESTION_PROMPT,\n",
    "#                                                      QA_PROMPT)\n",
    "\"\"\"Create a ChatVectorDBChain for question/answering.\"\"\"\n",
    "# from langchain.callbacks.base import AsyncCallbackManager\n",
    "from langchain.callbacks.manager import AsyncCallbackManager\n",
    "# from langchain.callbacks.tracers import LangChainTracer\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "from langchain.callbacks.tracers import LangChainTracer\n",
    "import  openai\n",
    "\n",
    "from transformers import TFAutoModelForQuestionAnswering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conversational import conversatioalBase\n",
    "\n",
    "class conversatioalChatGPT(conversatioalBase):\n",
    "    \n",
    "    def __init__(self,embedding=None,retriver=None,chat_prompt_template=os.environ.get(\"CONDENSE_TEMPLATE\"),qa_template=os.environ.get(\"QA_TEMPLATE\")) -> None:\n",
    "        super().__init__(embedding,retriver)\n",
    "        self.chat_prompt_template=chat_prompt_template\n",
    "        self.qa_template=qa_template\n",
    "        \n",
    "    \n",
    "    def getDefaultEmbadding(self): \n",
    "        return OpenAIEmbeddings(\n",
    "            openai_api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        \n",
    "    \n",
    "    \n",
    "    def getConversational(self)-> ConversationalRetrievalChain:\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "        memory = ConversationBufferMemory(\n",
    "            memory_key='chat_history',\n",
    "            return_messages=False\n",
    "        )\n",
    "    \n",
    "        # def getretriver(self):\n",
    "        #     # return dbCroma\n",
    "        #     # return Faissindexdb(embedding=self.getDefaultEmbadding())\n",
    "        #     return self.retriver\n",
    "    \n",
    "\n",
    "        CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(self.chat_prompt_template)\n",
    "        QA_PROMPT= PromptTemplate.from_template(self.qa_template)\n",
    "        \n",
    "        # define two LLM models from OpenAI\n",
    "        question_gen_llm = ChatOpenAI(\n",
    "            temperature=0.2,\n",
    "            # max_tokens=2000,\n",
    "            # model_name=\"text-curie-001\" ,#text-davinci-003\",\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        return  ConversationalRetrievalChain.from_llm(\n",
    "            llm=question_gen_llm,\n",
    "            # chain_type='stuff',\n",
    "            chain_type=\"map_reduce\",\n",
    "            retriever=self.retriver.getDb().as_retriever(qa_template=QA_PROMPT, question_generator_template=CONDENSE_QUESTION_PROMPT),\n",
    "            memory=memory,\n",
    "            get_chat_history=lambda h: h,\n",
    "            # verbose=True,\n",
    "            # return_source_documents=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa=conversatioalChatGPT().getConversational()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Faissindexdb.__init__() missing 1 required positional argument: 'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mindexdb\u001b[39;00m \u001b[39mimport\u001b[39;00m Faissindexdb\n\u001b[1;32m      2\u001b[0m query\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mאיך אני לוקך משכנתה?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m fidb\u001b[39m=\u001b[39mFaissindexdb()\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(fidb\u001b[39m.\u001b[39mgetDb()\u001b[39m.\u001b[39msimilarity_search(query))\n\u001b[1;32m      5\u001b[0m docs \u001b[39m=\u001b[39m fidb\u001b[39m.\u001b[39mgetDb()\u001b[39m.\u001b[39msimilarity_search(query)\n",
      "\u001b[0;31mTypeError\u001b[0m: Faissindexdb.__init__() missing 1 required positional argument: 'embedding'"
     ]
    }
   ],
   "source": [
    "# from indexdb import Faissindexdb\n",
    "import indexdb\n",
    "query=\"איך אני לוקך משכנתה?\"\n",
    "fidb=indexdb.Faissindexdb()\n",
    "print(fidb.getDb().similarity_search(query))\n",
    "docs = fidb.getDb().similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'איך אני לוקך משכנתה?', 'chat_history': 'Human: מיסים\\nAI: נקודות זיכוי ממס ניתנות לפי מצב משפחתי, גיל, מין, השכלה, שירות צבאי ועוד. לכל נקודת זיכוי יש שווי כספי (הנקבע בכל שנה), כשנקודות הזיכוי מקטינות את הסכום שממנו מחושב המס.\\nHuman: מיסים\\nAI: There is no relevant text in the given portion of the document to answer this question.', 'answer': 'To calculate your mortgage, you should take into account the total cost of the property and your own equity. The maximum funding ratio that a buyer can receive from the bank for a mortgage is determined by the Bank of Israel. For a single apartment, the maximum funding ratio is 75%, which means that your own equity should be at least 25% of the property value. For a duplex apartment, the maximum funding ratio is 70%, which means that your own equity should be at least 30% of the property value. For an investment property, the maximum funding ratio is 50%, which means that your own equity should be at least 50% of the property value. Additionally, you should consider your monthly repayment ability, which should not exceed 1/3 of your net income after deducting your fixed expenses. It is recommended to leave a certain margin of safety in your calculations to avoid the need for additional loans due to unforeseen expenses. You can also use a mortgage calculator to estimate your monthly payments based on the loan amount, interest rate, and repayment period.'}\n"
     ]
    }
   ],
   "source": [
    "res = qa(\n",
    "        {\n",
    "            'question': query,\n",
    "            'chat_history': []\n",
    "        }\n",
    "    )\n",
    "print( res )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
